---
title: DeepLearn 学习笔记 - 02
hidden: true
katex: true
date: 2022-02-14 14:11:08
id: DeepLearning/02
sticky: 
categories:
- 学习笔记
tags:
- 深度学习
- Python
- 编程
---

用 Pytorch 实现房价预测  
{% post_link "DeepLearning学习笔记" "点击查看索引" %}

<!-- more -->

## 项目环境的配置  

进行项目时, 不论其大小, 都要进行较为规范与全面的操作, 以养成习惯, 并且能熟悉各种工具的使用.  

### 建立 Github 仓库

#### Github 的注册与配置

在学习过程中, 我们可以将自己的代码与笔记上传到 Github 上, 以便于分享与查看.  
首先注册一个 Github 的账号, 建立一个 repo(仓库).  

![](./github.png)
![](./repo.png)

然后在本地的 Terminal 中输入以下命令:  

```shell
git config --global user.name "Your Name"
git config --global user.email "YourEmail@example.com"
```

其中要更改为你在 Github 上注册的账号的 name 和 Email.  

#### SSH key 的配置

为了方便对 repo 的访问, 我们可以设置一下 Git SSH key.  

```shell
ssh-keygen -t rsa -C "YourEmail@example.com"
```

之后可能输入密码, 然后配置方面一路 Enter 即可, 默认配置足够使用.  
生成完成后在 **~/.ssh** 将看到两个文件:  

![](./ssh.png)

我这里已经生成过了, 所以多了一个 known_hosts 的文件, 第一次生成可能不会出现.  
然后进入 Github 界面, 点击右上角头像, 选择 **Settings** , 点击 **SSH and GPG keys** , 按下 **New SSH key** , 输入 **id_rsa.pub** 文件中的内容保存即可.  

![](./ssh.png)

输入: `ssh -T git@github.com` 测试, 出现选项输入 `yes` 即可, 配置成功会出现类似输出:  

![](./sshsuccess.png)

这样我们就可以愉快地使用 Github 啦~  

#### Clone 仓库至本地  

在 Github 上建立仓库后, 我们要在本地进行编辑, 所以需要将其 Clone 至本地.  
在本地建立一个新文件夹, 我建议命名为 **Git** , 以便于统一管理.  
在 Terminal 中, `cd` 至该文件夹中, 输入命令 `git clone yourURL`.  
其中, **yourURL** 是在你的远程仓库中复制的, 如下图:  

![](./gitclone.png)

然后就可以在本地与我们的 repo 愉快地玩耍啦~  

### Pandas 与 Matplotlib 的安装  

打开 Terminal, 输入命令:  

```shell
conda install pandas matplotlib -n DL
```

即可在 DL 环境中安装 Pandas 和 Matplotlib.  

## Pytorch 入门

### Tensor 的初始化  

在 Terminal 中 `cd` 至你的工作目录, 然后输入 `code .` 即可在当前目录下打开 VSCode.  
建立一个新的 **.ipynb** 文件, 我这里命名为 **code.ipynb**

![](./newfile.png)

在 VSCode 中打开该文件, 会进入如下界面:  

![](./code.png)

首先输入:

```python
%matplotlib inline
import torch
import numpy as np
import pandas
```

其中:  
1. `%matplotlib inline` 表示将 matplotlib 的图像输出插入到输出行中.  
2. `import ...` 将我们所需的三个 Packages 导入到 Python 中.  

按下 `Shift + Enter` 即可运行并创建下一个代码块.  
在 Pytorch 中, 数据的储存容器是 tensor, 我们可以通过以下代码创建新的 tensor:  

```python
a = torch.empty(3, 3)
b = torch.rand(3, 3)
c = torch.zeros(3, 3)
d = torch.ones(3, 3)
print(a, b, c, d, sep='\n')
```

输出如下:  

```
tensor([[-7.6264e-01,  4.5722e-41, -6.7857e-19],
        [ 3.0740e-41,  4.4842e-44,  0.0000e+00],
        [ 8.9683e-44,  0.0000e+00, -8.4501e-19]])
tensor([[0.1820, 0.9340, 0.9872],
        [0.9514, 0.6855, 0.7122],
        [0.5567, 0.9431, 0.8098]])
tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]])
tensor([[1., 1., 1.],
        [1., 1., 1.],
        [1., 1., 1.]])
```

这里我们通过 `dtype` 参数可以改变数据类型:  

```python
a = torch.empty(3, 3, dtype=int)
```

输出如下:  

```
tensor([[3616445622929465956, 6067528668160208178, 3688512107902023472],
        [6500718696040053038, 7309453675965983778, 8315168162784306286],
        [8367752027310484831, 7954801838398993778, 2459029315949324647]])
```

这里的数据类型就变成了 `int` 类型.  
Pytorch 有很多生成 tensor 的命令, 部分如下:  

```python
torch.empty(1, 2) # 生成一个 1*2 的不初始化的 tensor.  
torch.rand(1, 2) # 生成一个随机初始化的 tensor.  
torch.zero(1, 2) # 生成一个全 0 的 tensor.  
torch.ones(1, 2) # 生成一个全 1 的 tensor.  
torch.tensor([1, 2]) # 根据已有数据生成一个 tensor.  

device = 'cuda' # 设定 GPU 设备.  
a = torch.rand(4, 5)
a = a.to(device) # 将 a 移动到 GPU.  
b = a.new_ones(3, 4)  # 根据 a 的属性生成新的全 1 的 tensor.  
c = ones_like(a) # 根据 a 的属性生成新的全 1 的 tensor.  

# Tensor 与 numpy array 共用同一内存空间, 改变一个另一个会随之改变.  
np_array = np.array([1, 2])
d = torch.from_numpy(np_array) # 将 numpy array 转换为 tensor.  
e = d.numpy() # 将 tensor 转换为 numpy array.  

a.shape # a 的维数.  
a.dtype # a 的数据类型.  
a.device # a 的存储设备.  
```

### Tensor 的运算  

```python
tensor = torch.ones(3, 4)

# 判断当前环境GPU是否可用, 然后将tensor导入GPU内运行
if torch.cuda.is_available():
    tensor = tensor.to('cuda')
```

下列是 tensor 的部分运算:  

```python
# Tensor 的索引与切片.  
t1 = tensor[:, 1]
t1[:] = 0
print(tensor) # 这里可以看到, tensor 切片与 tensor 共享内存地址.  

# Tensor 的拼接.  
t2 = torch.cat([tensor, tensor, tensor], dim = 1) # 三个 tensor 在 1 维拼接.  
print(t2)

# Tensor 的对应乘法.  
print(tensor.mul(tensor))
print(tensor * tensor)

# Tensor 的矩阵乘法
print(tensor.matmul(tensor.T))
print(tensor @ tensor.T) # tensor.T 表示 tensor 的转置.  
```

## 梯度下降  

在数学中, 对于一个函数, 我们知道沿梯度方向函数增加速度最快, 而 **沿梯度反向下降速度最快** . 在深度学习中, 我们就利用梯度来实现函数误差最小化.  
定义一个原函数:  

$$
f(x_1, x_2) = \omega_1^0x_1 + \omega_2^0x_2 + b_0
$$

我们只知道其部分输入与输出, 需要根据这些数据来预测该函数.  
定义一个预测函数:  

$$
g(x_1, x_2) = \omega_1x_1 + \omega_2x_2 + b
$$

我们拥有一个 **训练数据集(training data set)** , 内有许多 **样本(sample)** , 自变量为 **特征(feature)** , 其真实函数值为 **标签(label)** .  
为了方便书写, 下以首字母或前三个字母为缩写: TDS, SAM, FEA, LAB.  
取 TDS 的一个子集, 将其 FEA 代入预测函数, 得到一组预测值:  

$$
g(x_1^1, x_2^1), g(x_1^2, x_2^2), \cdots, g(x_1^n, x_2^n)
$$

得到误差:  

$$
l_i(x_1^i, x_2^i) = \frac{1}{2}[f(x_1, x_2) - g(x_1, x_2)]^2
$$

将这一子集的所有误差取平均, 得到 **损失函数(loss function)** :  

$$
loss(\omega_1, \omega_2, b) = \frac{1}{n}\sum_{i = 1}^{n}l_i
$$

通过对 loss function 中的 $\omega_1, \omega_2$ 偏微分, 得到其 **梯度(grad)** , 将 $\omega_1, \omega_2$ 减去某个值与其偏导数的乘积, 即可完成一次优化:  

$$
\omega_i \gets \omega_i - \eta \cdot loss
$$

其中 $\eta$ 为一个正数, 我们称之为 **学习率(learning rate)** , 其在大部分情况需要人为设置, 因此称为 **超参数(hyperparameter)** , 其数值不能过小, 否则训练时间会过长, 如果过大, 则会影响精确度. 因此, 我们经常在训练初期使用较高的 LR, 而在梯度变小后采用更小的 LR.  

## 房价预测  

### 准备工作  

首先前往 [Kaggle 比赛官网](https://www.kaggle.com/c/house-prices-advanced-regression-techniques) 获取数据集, 我放到了我的 Github 的 [DL_Learning](https://github.com/Jk-Cheung/DL_Learning) 中, 可以直接 clone.  
创建一个文件夹, 这里我创建为 **HousePrice** , 将 TDS 放入其中的文件夹 **data** 中, 同时在 **HousePrice** 中创建一个 **ipynb** 的文件, 我命名为 **code.ipynb**  
在 **code.ipynb** 中书写代码:  

```python
%matplotlib inline
import torch
import numpy as np
import torch.nn as nn
import pandas as pd
import sys


torch.set_default_tensor_type(torch.FloatTensor) # 设置 tensor 默认数据类型为 float.  
```

读取文件并获取其信息:  

```python
train_data = pd.read_csv('./data/train.csv')
test_data = pd.read_csv('./data/test.csv')
print(train_data.shape, test_data.shape, sep='\n')
```

得到输出:  

```
(1460, 81)
(1459, 80)
```

可以使用 VSCode 的 **Excel Viewer** 插件以表格形式展示 csv 文件, 如下图:  

![](./excelviewer.png)

我们可以看到, **Id** 这一 FEA 只是方便记录, 而对房价不会产生影响, 所以我们将其排除在外, 只使用其他 79 个 FEA:  

```python
all_fea = pd.concat([train_data.iloc[:, 1:], test_data.iloc[:, 1:]])
```

这里 `pd.concat` 指横向连接, 而 `data.iloc` 指按照指定行列提取数据.  

### 数据预处理  

对于 **数值类型** 的数据, 我们取其与平均值的差/标准差 为特征值, 对于缺失的数据, 可直接取为 0:  

```python
num_fea = all_fea.dtypes[all_fea.dtypes != 'object'].index
all_fea[num_fea] = all_fea[num_fea].apply(
    lambda x: (x - x.mean()) / (x.std())
    )
all_fea[num_fea] = all_fea[num_fea].fillna(0)
```

这里对 DataFrame 的操作有些复杂, 我们逐步分析:  

- `all_fea.dtypes != 'object'` 这里是检测所有数据是否为 'object' (即是否为数值类型) . 其返回值为 **Series** . 其中 data 为 `True` 或 `False` .  
- `all_fea.dtypes[all_fea.dtypes != 'object']` 返回所有 **数值类型** 的数据, 其 data 为 数据类型.  
- `all_fea.dtypes[all_fea.dtypes != 'object'].index` 取所有 **数值类型** 的数据的 **index** .  

`print` 一下就能看出来:  

```python
Index(['MSSubClass', 'LotFrontage', 'LotArea', 'OverallQual', 'OverallCond',
       'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2',
       'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF',
       'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath',
       'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces',
       'GarageYrBlt', 'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF',
       'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal',
       'MoSold', 'YrSold', 'SalePrice'],
      dtype='object')
```

之后是:  

- `all_fea[num_fea] = all_fea[num_fea].apply(lambda x: (x - x.mean()) / (x.std()))` Pandas 中, `DataFrame.apply(func, axis=0, raw=False, result_type=None, args=(), **kwargs)`, 所以参数我们需要写一个函数, 这里就使用了 Python 的 lambda 函数. 此函数指: 每一个数值减去平均值, 然后比上标准差. 这就完成了 **非缺失数据** 的标准化.  
- `all_fea[num_fea] = all_fea[num_fea].fillna(0)` 利用 `fillna` 函数将 **缺省值** 补充为 **0** , 因为上一步已经将其他数据标准化, 缺省指取平均值的话, 就可以直接补为 0.  

接下来处理 **离散值**:  

```python
all_fea = pd.get_dummies(all_fea, dummy_na=True)
```

函数 `pd.get_dummies` 